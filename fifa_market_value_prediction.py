# -*- coding: utf-8 -*-
"""FIFA market value prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CvCv0VlOmXp42pGqEWnGXPYMWNAUog1B
"""

!pip install eli5

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import eli5
from eli5.sklearn import PermutationImportance
from collections import Counter
import missingno as msno
from collections import defaultdict

import csv
import warnings
warnings.filterwarnings('ignore')
import plotly
sns.set_style('darkgrid')

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/My Drive/Fifa 19/data.csv', index_col = False)

df.shape

"""Cleaning data

Remove unnecessary columns
"""

df.drop(['Unnamed: 0','ID', 'Photo','Flag','Club Logo','Body Type', 'Real Face'],axis=1,inplace=True)

"""Checking values"""

msno.bar(df,(20,5),color='green', labels=True, fontsize= 10)

"""Delete players whose position is null, cause they have very little information"""

d = df.copy()
pos_nl = d[d['Position'].isnull()].index.tolist()
print ('Number of null positions: ', len(pos_nl))
d.drop(d.index[pos_nl],inplace= True)
pos_nl = d[d['Position'].isnull()].index.tolist()
print ('After dropping null values: ', len(pos_nl))

"""Remaining null columns:"""

pd.options.display.max_columns = None

obj= d.isnull().sum()
for key,value in obj.iteritems():
    if value !=0:
      print(key,",",value)

"""Inspecting Null club players"""

cols = ['Wage', 'Value', 'Release Clause', 'Joined','Loaned From','Contract Valid Until' ]
for col in cols:
  print('set for ', col)
  print( set(d[d['Club'].isnull()][col]))

"""After inspecting null club players, we can colude that these players are free agent players, that's why their  wages and values are 0. They also don't have any join date, contract expiration date or release clause. So, we will convert the null club players to free agents.

Replace null values of Club, Contract Valid Until, Joined, Loaned From

Remove date from Joined, Contract Valid Until. keep only year portion
"""

d['Club'].fillna('Free Agent', inplace= True)
d['Loaned From'].fillna('None', inplace= True)
cols= ['Joined', 'Contract Valid Until']
sep = ','
for col in cols:
  d[col].fillna(-1, inplace= True)
  d[col]= d[col].astype(str)
  d[col] = [word.split(sep, 2)[1] if len(word.split(sep, 2))==2 else word for word in d[col]]
  d[col]= d[col].astype(int)

"""Inspecting null values for attribute range: LS to RB"""

cols = d.loc[:,'LS':'RB'].keys().tolist()
for col in cols:
  col_nl = set(d[d[col].isnull()]['Position'])
  print('Position for which ', col, 'is null: ', col_nl)

"""Removing +... part from LS to RB columns"""

sep = '+'
for col in cols:
  d[col].fillna(0,inplace = True)
  d[col]= d[col].astype(str)
  d[col] = [word.split(sep, 1)[0] for word in d[col]]
  d[col]= d[col].astype(float)

"""Function to convert Height(ft) into Height(inches)"""

def parse_ht(ht):
    # format: 7'0.0"
    ht_ = ht.split("'")
    ft_ = float(ht_[0])
    in_ = float(ht_[1].replace("\"",""))
    return (12*ft_) + in_

"""Convert the following columns from string into numbers"""

d['Release Clause'].fillna(-1,inplace = True)
cols= ['Wage', 'Value', 'Release Clause']
for col in cols:
  d[col]= d[col].astype(str)
  d[col] = d[col].str.replace('â‚¬', '',1)
  d[col] = (d[col].str.replace(r'[KM]+$', '', regex=True).astype(float) * df[col].str.extract(r'[\d\.]+([KM]+)', expand=False).fillna(1).replace(['K','M'], [10**3, 10**6]).astype(int))
  d[col]= d[col].astype(float)
d['Weight'] = d['Weight'].str.replace('lbs', '',1).astype(float)


#d['Height'] = d['Height'].astype(float)
d['Height'] = d["Height"].apply(lambda x:parse_ht(x))

d['Jersey Number'] = d['Jersey Number'].astype(int)
for col in d.select_dtypes(include='object').keys().tolist():
  d[col] = d[col].astype(str)

d.info()

"""split work rate into two columns - Attacking work rate and Defensive work rate"""

d[['Attack Work Rate', 'Defense Work Rate']] = d['Work Rate'].str.split('/', 1, expand=True)
d.drop(['Work Rate'],axis=1,inplace=True)
set(d['Defense Work Rate'])

for col in d.select_dtypes(include='object').keys().tolist():
  print (col, ': ', len(set(d[col])))

"""Convert the following columns to category"""

cat_columns = ['Preferred Foot', 'Position', 'Attack Work Rate', 'Defense Work Rate' ]
for col in cat_columns:
  d[col] = d[col].astype('category')
d[cat_columns] = d[cat_columns].apply(lambda x: x.cat.codes)

d

d.to_csv('/content/drive/My Drive/Fifa 19/clean-data-2.csv', index = False)

from bs4 import BeautifulSoup

soup = BeautifulSoup(open('/content/drive/My Drive/Fifa 19/club_rankings.html'), "html.parser")

table = soup.find("table", attrs={"class":"t1"})

# The first tr contains the field names.
headings= ['rank', 'position_change', 'club', 'country', '11/12', '12/13', '13/14', '14/15', '15/16', '16/17', '17/18', '18/19', '19/20', '20/21', 'TitlePoints', 'CountryPart', 'TotalPoints']

csv_file = open('/content/drive/My Drive/Fifa 19/club_rank.csv', 'w')  
writer = csv.DictWriter(csv_file, fieldnames=headings)
writer.writeheader()
datasets = []
for row in table.find_all("tr")[1:]:
    d1 =  [td.get_text() for td in row.find_all("th")]
    d2 = [td.get_text() for td in row.find_all("td")]
    d = d2 + d1

    datasets.append(d)
    dct ={}
    for  i, h in enumerate(headings):
      dct[h] = d[i]
    print (dct)
    writer.writerow(dct)
for dataset in datasets:
  print (dataset)

csv_file.close()

cdf = (set(df['Club']))
ccr = set(cr['club'])
common = list(set(ccr).intersection((cdf)))

ccr=  [i.lower() for i in ccr]
ccr

len(cdf)

len(common)

common = list(common)